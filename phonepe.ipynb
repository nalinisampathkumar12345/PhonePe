{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json  # Importing the json module\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "#AGGREGATOR TRANSACTION \n",
    "############################################################ \n",
    "path1 = \"C:/AL ML/Project2-phonepe/pulse/data/aggregated/transaction/country/india/state/\"\n",
    "agg_trans_list = os.listdir(path1)\n",
    "#print(agg_trans_list)\n",
    "\n",
    "columns1 = {\"States\":[],\"Year\": [],\"Quater\":[],\"TransactionType\": [], \"TransactionCount\":[],\"TransactionAmount\":[]}\n",
    "\n",
    "# setting the path of each state\n",
    "for state in agg_trans_list:\n",
    "    curr_states = path1+state+\"/\"\n",
    "    #print(curr_states)\n",
    "    year_list = os.listdir(curr_states)\n",
    "    #print(year_list)\n",
    "    for yr in year_list:\n",
    "        curr_yr = curr_states+yr+\"/\"\n",
    "        #print(curr_yr)\n",
    "        yearFileList  = os.listdir(curr_yr)\n",
    "        #print(yearFileList)\n",
    "        for file in yearFileList:\n",
    "            data = open(curr_yr+file,\"r\")\n",
    "            #print(data)\n",
    "\n",
    "            A = json.load(data)\n",
    "            for i in A[\"data\"][\"transactionData\"]:\n",
    "              name = i[\"name\"]\n",
    "              count = i[\"paymentInstruments\"][0][\"count\"]\n",
    "              amount = i[\"paymentInstruments\"][0][\"amount\"]\n",
    "\n",
    "              columns1[\"TransactionType\"].append(name)\n",
    "              columns1[\"TransactionCount\"].append(count)\n",
    "              columns1[\"States\"].append(state)\n",
    "              columns1[\"Year\"].append(yr)\n",
    "              columns1[\"Quater\"].append(int(file.split(\".\")[0]))\n",
    "              columns1[\"TransactionAmount\"].append(amount)\n",
    "#print(columns1)\n",
    "aggregator_transaction  = pd.DataFrame(columns1)\n",
    "#print(aggregator_transaction)\n",
    "\n",
    "connection = mysql.connector.connect(\n",
    "    host=\"localhost\",          # Your MySQL server address\n",
    "    port= \"3306\",\n",
    "    user=\"root\",      # Your MySQL username\n",
    "    password=\"Sai@12345\",  # Your MySQL password\n",
    "    database=\"PhonePeDB\"   # Your MySQL database name\n",
    ")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Delete the table if it exists\n",
    "delete_table_query = \"DROP TABLE IF EXISTS agg_transactions;\"\n",
    "cursor.execute(delete_table_query)\n",
    "\n",
    "# Create a new table\n",
    "\n",
    "create_query =\"\"\"CREATE TABLE IF NOT EXISTS agg_transactions (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    State VARCHAR(255),\n",
    "    Year INT,\n",
    "    Quarter INT,\n",
    "    TransactionType VARCHAR(255),\n",
    "    TransactionCount INT,\n",
    "    TransactionAmount FLOAT\n",
    ");\"\"\"\n",
    "\n",
    "cursor.execute(create_query)\n",
    "\n",
    "for index, row in aggregator_transaction.iterrows():\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO agg_transactions (State, Year, Quarter, TransactionType, TransactionCount, TransactionAmount)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    data_tuple = (\n",
    "        row[\"States\"],  # Adjusted to \"States\" to match DataFrame column names\n",
    "        row[\"Year\"],\n",
    "        int(row[\"Quater\"]),  # Adjusted to \"Quater\" to match DataFrame column names\n",
    "        row[\"TransactionType\"],\n",
    "        row[\"TransactionCount\"],\n",
    "        row[\"TransactionAmount\"]\n",
    "    )\n",
    "    cursor.execute(insert_query, data_tuple)\n",
    "\n",
    "# Commit the transaction\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "#AGGREGATOR INSURANCE\n",
    "##############################################################################\n",
    "\n",
    "# Define the path for the data\n",
    "path2 = \"C:/AL ML/Project2-phonepe/pulse/data/aggregated/insurance/country/india/state/\"\n",
    "agg_insurance_list = os.listdir(path2)\n",
    "\n",
    "# Initialize the columns for the DataFrame\n",
    "columns2 = {\n",
    "    \"States\": [],\n",
    "    \"Year\": [],\n",
    "    \"Quater\": [],\n",
    "    \"TransactionType\": [],\n",
    "    \"TransactionCount\": [],\n",
    "    \"TransactionAmount\": [],\n",
    "    \"From\": [],\n",
    "    \"To\": []\n",
    "}\n",
    "\n",
    "# Parse through each state and year to extract the data\n",
    "for state in agg_insurance_list:\n",
    "    curr_states = path2 + state + \"/\"\n",
    "    year_list = os.listdir(curr_states)\n",
    "    for yr in year_list:\n",
    "        curr_yr = curr_states + yr + \"/\"\n",
    "        yearFileList = os.listdir(curr_yr)\n",
    "        #print(yearFileList)\n",
    "        for file in yearFileList:\n",
    "            with open(curr_yr + file, \"r\") as data:\n",
    "                B = json.load(data)\n",
    "                from_timestamp = B[\"data\"][\"from\"]\n",
    "                to_timestamp = B[\"data\"][\"to\"]\n",
    "\n",
    "                # Convert milliseconds to datetime objects\n",
    "                from_date = datetime.utcfromtimestamp(from_timestamp / 1000)\n",
    "                to_date = datetime.utcfromtimestamp(to_timestamp / 1000)\n",
    "\n",
    "                for i in B[\"data\"][\"transactionData\"]:\n",
    "                    name = i[\"name\"]\n",
    "                    count = i[\"paymentInstruments\"][0][\"count\"]\n",
    "                    amount = i[\"paymentInstruments\"][0][\"amount\"]\n",
    "\n",
    "                    columns2[\"TransactionType\"].append(name)\n",
    "                    columns2[\"TransactionCount\"].append(count)\n",
    "                    columns2[\"States\"].append(state)\n",
    "                    columns2[\"Year\"].append(yr)\n",
    "                    columns2[\"Quater\"].append(int(file.split(\".\")[0]))\n",
    "                    columns2[\"TransactionAmount\"].append(amount)\n",
    "                    columns2[\"From\"].append(from_date)\n",
    "                    columns2[\"To\"].append(to_date)\n",
    "\n",
    "# Create a DataFrame with the parsed data\n",
    "aggregator_insurance = pd.DataFrame(columns2)\n",
    "#print(aggregator_insurance)\n",
    "\n",
    "\n",
    "\n",
    "# Drop the table if it exists\n",
    "delete_table_query = \"DROP TABLE IF EXISTS agg_insurance;\"\n",
    "cursor.execute(delete_table_query)\n",
    "\n",
    "# Create the new table with the necessary columns\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE agg_insurance (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    State VARCHAR(255),\n",
    "    Year INT,\n",
    "    Quarter INT,\n",
    "    TransactionType VARCHAR(255),\n",
    "    TransactionCount INT,\n",
    "    TransactionAmount FLOAT,\n",
    "    `From` DATETIME,\n",
    "    `To` DATETIME\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)  # Corrected line\n",
    "\n",
    "# Insert the data into the newly created table\n",
    "for index, row in aggregator_insurance.iterrows():\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO agg_insurance (State, Year, Quarter, TransactionType, TransactionCount, TransactionAmount, `From`, `To`)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    data_tuple = (\n",
    "        row[\"States\"],\n",
    "        row[\"Year\"],\n",
    "        int(row[\"Quater\"]),\n",
    "        row[\"TransactionType\"],\n",
    "        row[\"TransactionCount\"],\n",
    "        row[\"TransactionAmount\"],\n",
    "        row[\"From\"],\n",
    "        row[\"To\"]\n",
    "    )\n",
    "    cursor.execute(insert_query, data_tuple)\n",
    "\n",
    "# Commit the transaction\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "#AGGREGATOR USER\n",
    "######################################################################################## \n",
    "\n",
    "path3 = \"C:/AL ML/Project2-phonepe/pulse/data/aggregated/user/country/india/state/\"\n",
    "agg_user_list = os.listdir(path3)\n",
    "#print(agg_trans_list)\n",
    "\n",
    "columns3 = {\"Brands\":[],\"Year\": [],\"Quater\":[], \"TransactionCount\":[],\"Percentage\":[],\"States\":[]}\n",
    "\n",
    "# setting the path of each state\n",
    "for state in agg_user_list:\n",
    "    curr_states = path3+state+\"/\"\n",
    "    #print(curr_states)\n",
    "    year_list = os.listdir(curr_states)\n",
    "    #print(year_list)\n",
    "    for yr in year_list:\n",
    "        curr_yr = curr_states+yr+\"/\"\n",
    "        #print(curr_yr)\n",
    "        yearFileList  = os.listdir(curr_yr)\n",
    "        #print(yearFileList)\n",
    "        for file in yearFileList:\n",
    "            data = open(curr_yr+file,\"r\")\n",
    "        \n",
    "            C = json.load(data)\n",
    "           \n",
    "            try:\n",
    "                for i in  C[\"data\"][\"usersByDevice\"]:\n",
    "                    brand = i[\"brand\"]\n",
    "                    count = i[\"count\"]\n",
    "                    percentage = i[\"percentage\"]\n",
    "\n",
    "                    columns3[\"Brands\"].append(brand)\n",
    "                    columns3[\"TransactionCount\"].append(count)\n",
    "                    columns3[\"Percentage\"].append(percentage)\n",
    "                    columns3[\"Year\"].append(yr)\n",
    "                    columns3[\"Quater\"].append(int(file.split(\".\")[0]))\n",
    "                    columns3[\"States\"].append(state)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "aggregator_user = pd.DataFrame(columns3)\n",
    "\n",
    "delete_table_query = \"DROP TABLE IF EXISTS agg_user;\"\n",
    "cursor.execute(delete_table_query)\n",
    "\n",
    "# Create the new table with the necessary columns\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE agg_user (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    Brands VARCHAR(255),\n",
    "    Year INT,\n",
    "    Quarter INT,\n",
    "    TransactionCount INT,\n",
    "    Percentage FLOAT,\n",
    "    State VARCHAR(255)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "# Insert the data into the newly created table\n",
    "for index, row in aggregator_user.iterrows():\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO agg_user (Brands, Year, Quarter, TransactionCount, Percentage, State)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    data_tuple = (\n",
    "        row[\"Brands\"],\n",
    "        row[\"Year\"],\n",
    "        int(row[\"Quater\"]),\n",
    "        row[\"TransactionCount\"],\n",
    "        row[\"Percentage\"],\n",
    "        row[\"States\"]\n",
    "    )\n",
    "    cursor.execute(insert_query, data_tuple)\n",
    "\n",
    "# Commit the transaction\n",
    "connection.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json', '2.json', '3.json', '4.json']\n",
      "['1.json']\n"
     ]
    }
   ],
   "source": [
    "#MAP transaction \n",
    "#####################################################################################C:\\AL ML\\Project2-phonepe\\pulse\\data\\map\\transaction\n",
    "path4 = \"C:/AL ML/Project2-phonepe/pulse/data/map/transaction/hover/country/india/state/\"\n",
    "map_trans_list = os.listdir(path4)\n",
    "#print(map_trans_list)\n",
    "\n",
    "columns4 = {\"States\":[],\"Year\": [],\"Quater\":[],\"TransactionType\": [], \"TransactionCount\":[],\"TransactionAmount\":[]}\n",
    "\n",
    "# setting the path of each state\n",
    "for state in map_trans_list:\n",
    "    curr_states = path4+state+\"/\"\n",
    "    #print(curr_states)\n",
    "    year_list = os.listdir(curr_states)\n",
    "    #print(year_list)\n",
    "    for yr in year_list:\n",
    "        curr_yr = curr_states+yr+\"/\"\n",
    "        #print(curr_yr)\n",
    "        yearFileList  = os.listdir(curr_yr)\n",
    "        print(yearFileList)\n",
    "        for file in yearFileList:\n",
    "            data = open(curr_yr+file,\"r\")\n",
    "            #print(data)\n",
    "            D= json.load(data)\n",
    "            for item in D[\"data\"][\"hoverDataList\"]:\n",
    "                    name = item[\"name\"]\n",
    "                    for metric in item[\"metric\"]:\n",
    "                        transaction_type = metric[\"type\"]\n",
    "                        count = metric[\"count\"]\n",
    "                        amount = metric[\"amount\"]\n",
    "                        \n",
    "                        # Append the extracted data to the columns4 dictionary\n",
    "                        columns4[\"TransactionType\"].append(transaction_type)\n",
    "                        columns4[\"TransactionCount\"].append(count)\n",
    "                        columns4[\"TransactionAmount\"].append(amount)\n",
    "                        columns4[\"States\"].append(state)\n",
    "                        columns4[\"Year\"].append(yr)\n",
    "                        columns4[\"Quater\"].append(int(file.split(\".\")[0]))\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "map_transaction = pd.DataFrame(columns4)\n",
    "#print(map_transaction)\n",
    "\n",
    "\n",
    "\n",
    "# Delete the table if it exists\n",
    "delete_table_query = \"DROP TABLE IF EXISTS map_transactions;\"\n",
    "cursor.execute(delete_table_query)\n",
    "\n",
    "# Create a new table\n",
    "create_query =\"\"\"CREATE TABLE IF NOT EXISTS map_transactions (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    State VARCHAR(255),\n",
    "    Year INT,\n",
    "    Quarter INT,\n",
    "    TransactionType VARCHAR(255),\n",
    "    TransactionCount INT,\n",
    "    TransactionAmount FLOAT\n",
    ");\"\"\"\n",
    "\n",
    "cursor.execute(create_query)\n",
    "\n",
    "for index, row in map_transaction.iterrows():\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO map_transactions (State, Year, Quarter, TransactionType, TransactionCount, TransactionAmount)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    data_tuple = (\n",
    "        row[\"States\"],  # Adjusted to \"States\" to match DataFrame column names\n",
    "        row[\"Year\"],\n",
    "        int(row[\"Quater\"]),  # Adjusted to \"Quater\" to match DataFrame column names\n",
    "        row[\"TransactionType\"],\n",
    "        row[\"TransactionCount\"],\n",
    "        row[\"TransactionAmount\"]\n",
    "    )\n",
    "    cursor.execute(insert_query, data_tuple)\n",
    "\n",
    "# Commit the transaction\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "#MAP insurance \n",
    "###########################################################################################\n",
    "\n",
    "# Define the path for the data\n",
    "path5 = \"C:/AL ML/Project2-phonepe/pulse/data/map/insurance/country/india/state/\"\n",
    "map_insurance_list = os.listdir(path5)\n",
    "\n",
    "# Initialize the columns for the DataFrame\n",
    "columns5 = {\n",
    "    \"States\": [],\n",
    "    \"Year\": [],\n",
    "    \"Quater\": [],\n",
    "    \"District\": [],\n",
    "    \"Latitude\": [],\n",
    "    \"Longitude\": [],\n",
    "    \"Metric\": [],\n",
    "}\n",
    "\n",
    "# Parse through each state and year to extract the data\n",
    "for state in map_insurance_list:\n",
    "    curr_states = path5 + state + \"/\"\n",
    "    year_list = os.listdir(curr_states)\n",
    "    for yr in year_list:\n",
    "        curr_yr = curr_states + yr + \"/\"\n",
    "        yearFileList = os.listdir(curr_yr)\n",
    "        for file in yearFileList:\n",
    "            with open(curr_yr + file, \"r\") as data:\n",
    "                E = json.load(data)\n",
    "                for entry in E[\"data\"][\"data\"][\"data\"]:\n",
    "                    latitude = entry[0]  # Latitude\n",
    "                    longitude = entry[1]  # Longitude\n",
    "                    metric = entry[2]  # Metric\n",
    "                    district = entry[3]  # District label\n",
    "                    print(\"latitude\")\n",
    "                    print(latitude)\n",
    "                    # Append the data to the DataFrame columns\n",
    "                    columns5[\"States\"].append(state)\n",
    "                    columns5[\"Year\"].append(yr)\n",
    "                    columns5[\"Quater\"].append(int(file.split(\".\")[0]))\n",
    "                    columns5[\"District\"].append(district)\n",
    "                    columns5[\"Latitude\"].append(latitude)\n",
    "                    columns5[\"Longitude\"].append(longitude)\n",
    "                    columns5[\"Metric\"].append(metric)\n",
    "\n",
    "# Create a DataFrame with the parsed data\n",
    "map_insurance = pd.DataFrame(columns5)\n",
    "\n",
    "# Drop the table if it exists\n",
    "delete_table_query = \"DROP TABLE IF EXISTS map_insurance;\"\n",
    "cursor.execute(delete_table_query)\n",
    "\n",
    "# Create the new table with the necessary columns\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE map_insurance (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    State VARCHAR(255),\n",
    "    Year INT,\n",
    "    Quarter INT,\n",
    "    District VARCHAR(255),\n",
    "    Latitude DECIMAL(10, 8),\n",
    "    Longitude DOUBLE,\n",
    "    Metric FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "# Insert the data into the newly created table\n",
    "for index, row in map_insurance.iterrows():\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO map_insurance (State, Year, Quarter, District, Latitude, Longitude, Metric)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    data_tuple = (\n",
    "        row[\"States\"],\n",
    "        row[\"Year\"],\n",
    "        row[\"Quater\"],\n",
    "        row[\"District\"],\n",
    "        row[\"Latitude\"],\n",
    "        row[\"Longitude\"],\n",
    "        row[\"Metric\"]\n",
    "    )\n",
    "    cursor.execute(insert_query, data_tuple)\n",
    "\n",
    "# Commit the transaction\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "#MAP user \n",
    "#############################################################################################\n",
    "\n",
    "path6 = \"C:/AL ML/Project2-phonepe/pulse/data/map/user/hover/country/india/state/\"\n",
    "map_user_list = os.listdir(path6)\n",
    "#print(map_user_list)\n",
    "\n",
    "columns6 = {\"Brands\":[],\"Year\": [],\"Quater\":[], \"TransactionCount\":[],\"Percentage\":[],\"States\":[]}\n",
    "\n",
    "# setting the path of each state\n",
    "for state in map_user_list:\n",
    "    curr_states = path3+state+\"/\"\n",
    "    #print(curr_states)\n",
    "    year_list = os.listdir(curr_states)\n",
    "    #print(year_list)\n",
    "    for yr in year_list:\n",
    "        curr_yr = curr_states+yr+\"/\"\n",
    "        #print(curr_yr)\n",
    "        yearFileList  = os.listdir(curr_yr)\n",
    "        #print(yearFileList)\n",
    "        for file in yearFileList:\n",
    "            data = open(curr_yr+file,\"r\")\n",
    "        \n",
    "            F = json.load(data)\n",
    "           \n",
    "            try:\n",
    "                for i in  F[\"data\"][\"usersByDevice\"]:\n",
    "                    brand = i[\"brand\"]\n",
    "                    count = i[\"count\"]\n",
    "                    percentage = i[\"percentage\"]\n",
    "\n",
    "                    columns3[\"Brands\"].append(brand)\n",
    "                    columns3[\"TransactionCount\"].append(count)\n",
    "                    columns3[\"Percentage\"].append(percentage)\n",
    "                    columns3[\"Year\"].append(yr)\n",
    "                    columns3[\"Quater\"].append(int(file.split(\".\")[0]))\n",
    "                    columns3[\"States\"].append(state)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "map_user = pd.DataFrame(columns3)\n",
    "\n",
    "delete_table_query = \"DROP TABLE IF EXISTS map_user;\"\n",
    "cursor.execute(delete_table_query)\n",
    "\n",
    "# Create the new table with the necessary columns\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE map_user (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    Brands VARCHAR(255),\n",
    "    Year INT,\n",
    "    Quarter INT,\n",
    "    TransactionCount INT,\n",
    "    Percentage FLOAT,\n",
    "    State VARCHAR(255)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "# Insert the data into the newly created table\n",
    "for index, row in map_user.iterrows():\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO map_user (Brands, Year, Quarter, TransactionCount, Percentage, State)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    data_tuple = (\n",
    "        row[\"Brands\"],\n",
    "        row[\"Year\"],\n",
    "        int(row[\"Quater\"]),\n",
    "        row[\"TransactionCount\"],\n",
    "        row[\"Percentage\"],\n",
    "        row[\"States\"]\n",
    "    )\n",
    "    cursor.execute(insert_query, data_tuple)\n",
    "\n",
    "# Commit the transaction\n",
    "connection.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to interrupt the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Permission denied (addr='tcp://127.0.0.1:9007'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Top INSURANCE\n",
    "#########################################################################################\n",
    "\n",
    "path7 = \"C:/AL ML/Project2-phonepe/pulse/data/top/insurance/country/india/state/\"\n",
    "top_insurance_list = os.listdir(path7)\n",
    "\n",
    "# Initialize the columns for the DataFrame\n",
    "columns7 = {\n",
    "    \"States\": [],\n",
    "    \"Year\": [],\n",
    "    \"Quater\": [],\n",
    "    \"TransactionAmount\": [],\n",
    "    \"TransactionCount\": [],\n",
    "    \"Pincode\": []  \n",
    "}\n",
    "\n",
    "# Parse through each state and year to extract the data\n",
    "for state in top_insurance_list:\n",
    "    curr_states = path7 + state + \"/\"\n",
    "    year_list = os.listdir(curr_states)\n",
    "    for yr in year_list:\n",
    "        curr_yr = curr_states + yr + \"/\"\n",
    "        yearFileList = os.listdir(curr_yr)\n",
    "        for file in yearFileList:\n",
    "            with open(curr_yr + file, \"r\") as data:\n",
    "                G = json.load(data)\n",
    "                for pin in G[\"data\"][\"pincodes\"]:\n",
    "                    entityname = pin[\"entityName\"]\n",
    "                    count = pin[\"metric\"][\"count\"]\n",
    "                    amount = pin[\"metric\"][\"amount\"]\n",
    "                    columns7[\"Year\"].append(yr)\n",
    "                    columns7[\"Quater\"].append(int(file.split(\".\")[0]))\n",
    "                    columns7[\"States\"].append(state)\n",
    "                    columns7[\"TransactionAmount\"].append(amount)\n",
    "                    columns7[\"TransactionCount\"].append(count)\n",
    "                    columns7[\"Pincode\"].append(entityname)\n",
    "top_insurance = pd.DataFrame(columns7)\n",
    "\n",
    "\n",
    "\n",
    "# Drop the table if it exists\n",
    "delete_table_query = \"DROP TABLE IF EXISTS top_insurance;\"\n",
    "cursor.execute(delete_table_query)\n",
    "\n",
    "# Create the new table with the necessary columns\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE top_insurance (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    State VARCHAR(255),\n",
    "    Year INT,\n",
    "    Quarter INT,\n",
    "    TransactionAmount FLOAT,\n",
    "    TransactionCount INT,\n",
    "    Pincode VARCHAR(20)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "# Insert the data into the newly created table\n",
    "for index, row in top_insurance.iterrows():\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO top_insurance (State, Year, Quarter, TransactionAmount, TransactionCount, Pincode)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    data_tuple = (\n",
    "        row[\"States\"],\n",
    "        row[\"Year\"],\n",
    "        int(row[\"Quater\"]),\n",
    "        row[\"TransactionAmount\"],\n",
    "        row[\"TransactionCount\"],\n",
    "        row[\"Pincode\"]\n",
    "    )\n",
    "    cursor.execute(insert_query, data_tuple)\n",
    "\n",
    "\n",
    "path_transaction = \"C:/AL ML/Project2-phonepe/pulse/data/top/transaction/country/india/state/\"\n",
    "top_transaction_list = os.listdir(path_transaction)\n",
    "\n",
    "# Initialize the columns for the DataFrame\n",
    "columns_transaction = {\n",
    "    \"States\": [],\n",
    "    \"Year\": [],\n",
    "    \"Quater\": [],\n",
    "    \"TransactionAmount\": [],\n",
    "    \"TransactionCount\": [],\n",
    "    \"Pincode\": []  \n",
    "}\n",
    "\n",
    "# Parse through each state and year to extract the data\n",
    "for state in top_transaction_list:\n",
    "    curr_states = path_transaction + state + \"/\"\n",
    "    year_list = os.listdir(curr_states)\n",
    "    for yr in year_list:\n",
    "        curr_yr = curr_states + yr + \"/\"\n",
    "        yearFileList = os.listdir(curr_yr)\n",
    "        for file in yearFileList:\n",
    "            with open(curr_yr + file, \"r\") as data:\n",
    "                G = json.load(data)\n",
    "                for pin in G[\"data\"][\"pincodes\"]:\n",
    "                    entityname = pin[\"entityName\"]\n",
    "                    count = pin[\"metric\"][\"count\"]\n",
    "                    amount = pin[\"metric\"][\"amount\"]\n",
    "                    columns_transaction[\"Year\"].append(yr)\n",
    "                    columns_transaction[\"Quater\"].append(int(file.split(\".\")[0]))\n",
    "                    columns_transaction[\"States\"].append(state)\n",
    "                    columns_transaction[\"TransactionAmount\"].append(amount)\n",
    "                    columns_transaction[\"TransactionCount\"].append(count)\n",
    "                    columns_transaction[\"Pincode\"].append(entityname)\n",
    "top_transaction = pd.DataFrame(columns_transaction)\n",
    "\n",
    "# Drop the existing table\n",
    "delete_table_query_transaction = \"DROP TABLE IF EXISTS top_transaction;\"\n",
    "cursor.execute(delete_table_query_transaction)\n",
    "\n",
    "# Create the new table\n",
    "create_table_query_transaction = \"\"\"\n",
    "CREATE TABLE top_transaction (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    State VARCHAR(255),\n",
    "    Year INT,\n",
    "    Quarter INT,\n",
    "    TransactionAmount FLOAT,\n",
    "    TransactionCount INT,\n",
    "    Pincode VARCHAR(20)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query_transaction)\n",
    "\n",
    "# Insert data into the table\n",
    "for index, row in top_transaction.iterrows():\n",
    "    insert_query_transaction = \"\"\"\n",
    "    INSERT INTO top_transaction (State, Year, Quarter, TransactionAmount, TransactionCount, Pincode)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    data_tuple_transaction = (\n",
    "        row[\"States\"],\n",
    "        row[\"Year\"],\n",
    "        int(row[\"Quater\"]),\n",
    "        row[\"TransactionAmount\"],\n",
    "        row[\"TransactionCount\"],\n",
    "        row[\"Pincode\"]\n",
    "    )\n",
    "    cursor.execute(insert_query_transaction, data_tuple_transaction)\n",
    "\n",
    "path_user = \"C:/AL ML/Project2-phonepe/pulse/data/top/user/country/india/state/\"\n",
    "top_user_list = os.listdir(path_user)\n",
    "\n",
    "# Initialize the columns for the DataFrame\n",
    "columns_user = {\n",
    "    \"States\": [],\n",
    "    \"Year\": [],\n",
    "    \"Quater\": [],\n",
    "    \"RegisteredUsers\": [],\n",
    "    \"Pincode\": []  \n",
    "}\n",
    "\n",
    "# Parse through each state and year to extract the data\n",
    "for state in top_user_list:\n",
    "    curr_states = path_user + state + \"/\"\n",
    "    year_list = os.listdir(curr_states)\n",
    "    for yr in year_list:\n",
    "        curr_yr = curr_states + yr + \"/\"\n",
    "        yearFileList = os.listdir(curr_yr)\n",
    "        for file in yearFileList:\n",
    "            with open(curr_yr + file, \"r\") as data:\n",
    "                G = json.load(data)\n",
    "                for pin in G[\"data\"][\"pincodes\"]:\n",
    "                    entityname = pin[\"entityName\"]\n",
    "                    registered_users = pin[\"metric\"][\"registeredUsers\"]\n",
    "                    columns_user[\"Year\"].append(yr)\n",
    "                    columns_user[\"Quater\"].append(int(file.split(\".\")[0]))\n",
    "                    columns_user[\"States\"].append(state)\n",
    "                    columns_user[\"RegisteredUsers\"].append(registered_users)\n",
    "                    columns_user[\"Pincode\"].append(entityname)\n",
    "top_user = pd.DataFrame(columns_user)\n",
    "\n",
    "# Drop the existing table\n",
    "delete_table_query_user = \"DROP TABLE IF EXISTS top_user;\"\n",
    "cursor.execute(delete_table_query_user)\n",
    "\n",
    "# Create the new table\n",
    "create_table_query_user = \"\"\"\n",
    "CREATE TABLE top_user (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    State VARCHAR(255),\n",
    "    Year INT,\n",
    "    Quarter INT,\n",
    "    RegisteredUsers INT,\n",
    "    Pincode VARCHAR(20)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query_user)\n",
    "\n",
    "# Insert data into the table\n",
    "for index, row in top_user.iterrows():\n",
    "    insert_query_user = \"\"\"\n",
    "    INSERT INTO top_user (State, Year, Quarter, RegisteredUsers, Pincode)\n",
    "    VALUES (%s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    data_tuple_user = (\n",
    "        row[\"States\"],\n",
    "        row[\"Year\"],\n",
    "        int(row[\"Quater\"]),\n",
    "        row[\"RegisteredUsers\"],\n",
    "        row[\"Pincode\"]\n",
    "    )\n",
    "    cursor.execute(insert_query_user, data_tuple_user)\n",
    "\n",
    "\n",
    "# Commit the transaction\n",
    "connection.commit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
